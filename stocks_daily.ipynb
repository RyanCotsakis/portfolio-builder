{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3146c9fd-179b-4911-889f-5e11da8dc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b6f1790-0eda-4f61-b93e-1782306194a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_ticker(ticker):\n",
    "    url = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=1483228800&period2=1767225600&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "    print(\"Fetching data for \" + ticker)\n",
    "    headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    with open(\"temp.csv\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    df = pd.read_csv(\"temp.csv\")\n",
    "    os.remove(\"temp.csv\")  # Remove the temporary CSV file\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "970ac1b4-ff02-406e-95c4-f17f5391d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common dates across all DataFrames\n",
    "def preprocess_dfs(tickers):\n",
    "    raw_dfs = [df_from_ticker(ticker) for ticker in tickers]\n",
    "    print(\"Done.\")\n",
    "    common_dates = set(raw_dfs[0][\"Date\"])\n",
    "    for df in raw_dfs[1:]:\n",
    "        common_dates.intersection_update(df[\"Date\"])\n",
    "\n",
    "    # Sort the common dates in descending order\n",
    "    common_dates = sorted(common_dates)\n",
    "    print(\"Using \" + str(len(common_dates)) + \" days.\")\n",
    "    print(\"Until \" + common_dates[-1] + \".\")\n",
    "\n",
    "    # Filter DataFrames to keep only common dates\n",
    "    filtered_dfs = []\n",
    "    for j, df in enumerate(raw_dfs):\n",
    "        i = 0\n",
    "        while (i < df.shape[0]):\n",
    "            if df[\"Date\"].iloc[i] not in common_dates:\n",
    "                df = df.iloc[list(set(range(df.shape[0])) - set([i]))]\n",
    "            else:\n",
    "                i += 1\n",
    "        df = df.reset_index(drop=True)\n",
    "        filtered_dfs.append(df[[\"High\", \"Open\", \"Low\", \"Close\"]])\n",
    "    for i, df in enumerate(filtered_dfs):\n",
    "        filtered_dfs[i] = np.log(df)\n",
    "\n",
    "    for i, df in enumerate(filtered_dfs):\n",
    "        df.columns = [tickers[i] + '_' + col if col != 'Date' else col for col in df.columns]\n",
    "\n",
    "    # Concatenate all dfs\n",
    "    concatenated_df = pd.concat(filtered_dfs, axis = 1)\n",
    "    print(\"Using {} features.\".format(concatenated_df.shape[1]))\n",
    "    return(concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b28120fc-9df4-4828-b8ab-566e78a2f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(preprocessed, filt, decay_constant=0.33):\n",
    "    n = preprocessed.shape[0]\n",
    "    Y = np.zeros((n, len(filt)))\n",
    "    Y_vectors = preprocessed[[ticker + \"_Close\" for ticker in filt]]\n",
    "    Y[n-1,] = Y_vectors.iloc[n-1]\n",
    "    for i in range(n - 2, -1, -1):\n",
    "        Y[i,] = (1-decay_constant)*Y_vectors.iloc[i+1] + decay_constant*Y[i+1,]\n",
    "    # drop the last observation\n",
    "    Y = Y[:-1,] - Y_vectors.drop(index=n-1)\n",
    "    X = preprocessed.drop(index=n-1)\n",
    "    n -= 1\n",
    "    \n",
    "    print(\"Training on X: \" + str(X.shape))\n",
    "    print(\"Training on Y: \" + str(Y.shape))\n",
    "    return (X, Y)\n",
    "\n",
    "def normalize(X, Y=None):\n",
    "    X_means = np.mean(X, axis=0)\n",
    "    X_stds = np.std(X, axis=0)\n",
    "    X_normalized = (X - X_means) / X_stds\n",
    "    if Y is None:\n",
    "        return X_normalized\n",
    "    Y_means = np.mean(Y, axis=0)\n",
    "    Y_normalized = Y - Y_means\n",
    "    return (X_normalized, Y_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4098b2f-d482-4a92-86b0-14503d8cd413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU; consider making n_epochs very small.\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08a2e105-22f1-4ebd-b379-067859e3c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioBuilder(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.h1 = nn.Linear(n_input, n_input)\n",
    "        self.h2 = nn.Linear(n_input, n_input)\n",
    "        self.lstm = nn.LSTM(n_input, n_hidden, n_layers)\n",
    "        self.out = nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.35)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.dropout(self.h1(x))\n",
    "        x = self.dropout(torch.tanh(self.h2(x)))\n",
    "        x, hidden = self.lstm(x.unsqueeze(0), hidden)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.squeeze(0)\n",
    "        x = F.softmax(self.out(x), dim=1)\n",
    "        return(x, hidden)\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data # match the datatype\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        return hidden if batch_size > 1 else tuple([h.view(self.n_layers, self.n_hidden) for h in hidden])\n",
    "\n",
    "def returns(portfolio, log_changes, sharpe=False):\n",
    "    if len(portfolio.shape) == 1:\n",
    "        portfolio = portfolio.unsqueeze(0)\n",
    "        log_changes = log_changes.unsqueeze(0)\n",
    "    if sharpe:\n",
    "        Sigma = torch.Tensor(np.array(Y.cov()))\n",
    "        aSigmaa = (torch.matmul(portfolio[:,:-1], Sigma) * portfolio[:,:-1]).sum(axis=1)\n",
    "        neg_loss_sharpe = -((portfolio[:,:-1] * log_changes).sum(axis=1)/torch.sqrt(aSigmaa) * (1 - portfolio[:,-1])).mean()\n",
    "        return(neg_loss_sharpe)\n",
    "    else:\n",
    "        neg_loss = -(portfolio[:,:-1] * log_changes).sum(axis=1).mean()\n",
    "        return(neg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22fed406-bdf5-4c6f-9959-a74c440f0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, n_epochs, batch_size=10, lr=0.001, clip=5, test_size=0.2, file=None):\n",
    "    start_at = X.shape[0] - batch_size * (X.shape[0]//batch_size)\n",
    "    all_indices = np.array(range(start_at, X.shape[0]))\n",
    "    all_indices = all_indices.reshape(batch_size,-1)\n",
    "    n = all_indices.shape[1]\n",
    "    use_for_test = [False if i/n < 1- test_size else True for i in range(n)]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "    \n",
    "    min_test_loss = float(\"inf\")\n",
    "    all_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "#         np.random.shuffle(train_indices)\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        for i in range(n):\n",
    "            inds = all_indices[:,i]\n",
    "            if use_for_test[i]:\n",
    "                rnn.eval()\n",
    "            else:\n",
    "                rnn.train()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            x = torch.Tensor(np.array(X.iloc[inds])).to(torch.float32)\n",
    "            y = torch.Tensor(np.array(Y.iloc[inds])).to(torch.float32)\n",
    "                \n",
    "\n",
    "            prediction, hidden = rnn(x, hidden)\n",
    "            hidden = tuple([h.data for h in hidden])\n",
    "#             print(hidden)\n",
    "            loss = criterion(prediction, y)\n",
    "    \n",
    "            if use_for_test[i]:\n",
    "                test_loss += loss\n",
    "            else:\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                train_loss += loss\n",
    "        train_loss = train_loss.item() / (n - np.sum(use_for_test))\n",
    "        test_loss = test_loss.item() / np.sum(use_for_test)\n",
    "        all_losses.append((train_loss, test_loss))\n",
    "        if epoch % 10 == 9:\n",
    "            print(\"Epochs: \" + str(epoch+1))\n",
    "            print(\"Train / Test loss: \" + \"{:.6f}\".format(train_loss) + \" / {:.6f}\".format(test_loss))\n",
    "        if test_loss < min_test_loss and file is not None:\n",
    "            print(\"Saving at epoch {}. Test loss of {}.\".format(epoch+1, test_loss))\n",
    "            min_test_loss = test_loss\n",
    "            torch.save({'model_state_dict': rnn.state_dict(),\n",
    "                        'tickers': tickers,\n",
    "                        'filt': filt,\n",
    "                        'sharpe': sharpe,\n",
    "                        'loss': test_loss}, file)\n",
    "\n",
    "    plt.plot(list(range(n_epochs)), [loss[0] for loss in all_losses])\n",
    "    plt.plot(list(range(n_epochs)), [loss[1] for loss in all_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35f52b4b-58de-48d5-8960-f5afa5f15d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START HERE ##\n",
    "\n",
    "model_file = 'top_stocks_2.pth'\n",
    "tickers = None\n",
    "filt = None\n",
    "\n",
    "new_model = False # train a new model?\n",
    "if new_model:\n",
    "    tickers = [\"AMH\", \"C\", \"FIS\", \"HUM\", \"ISRG\", \"LEA\", \"TREX\", \"UNP\", \"SPY\"]  # Example list of stock codes\n",
    "    filt = [\"AMH\", \"C\", \"FIS\", \"HUM\", \"ISRG\"] # the stocks to include in the portfolio\n",
    "    \n",
    "    preprocessed = preprocess_dfs(tickers)\n",
    "    rnn = PortfolioBuilder(preprocessed.shape[1], len(filt) + 1, preprocessed.shape[1])\n",
    "    print(rnn)\n",
    "    \n",
    "    sharpe = True # use the sharpe ratio or maximize profits?\n",
    "    X, Y = get_training_data(preprocessed, filt, decay_constant=0.5)\n",
    "    X, Y = normalize(X, Y)\n",
    "    criterion = lambda predicted, target: returns(predicted, target, sharpe)\n",
    "    train(X, Y, n_epochs=350, batch_size=10, test_size=0.2, file=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fc696e56-4cbc-44c9-8c3e-a5b940ebe458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AMH\n",
      "Fetching data for C\n",
      "Fetching data for FIS\n",
      "Fetching data for HUM\n",
      "Fetching data for ISRG\n",
      "Fetching data for LEA\n",
      "Fetching data for TREX\n",
      "Fetching data for UNP\n",
      "Fetching data for SPY\n",
      "Done.\n",
      "Using 1795 days.\n",
      "Until 2024-02-21.\n",
      "Using 36 features.\n",
      "Loaded 'top_stocks_2.pth' with a Sharpe loss of -0.16565536771501813.\n",
      "Using all 1795 days.\n",
      "Total assets: 1200.0 EUR\n",
      "Averages: {'AMH': 270.5932036621771, 'C': 291.6593368688267, 'FIS': 100.56072635629663, 'HUM': 198.009855946031, 'ISRG': 186.7575205451328, 'EUR CASH': 152.41935468950868}\n",
      "Portfolio: {'AMH': 88.563324, 'C': 1110.3098, 'FIS': 0.19449817, 'HUM': 0.23096834, 'ISRG': 0.68171114, 'EUR CASH': 0.019796515}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model_file is not None:\n",
    "    checkpoint = torch.load(model_file)\n",
    "    if tickers != checkpoint['tickers'] or filt != checkpoint['filt']:\n",
    "        filt = checkpoint['filt']\n",
    "        tickers = checkpoint['tickers']\n",
    "        preprocessed = preprocess_dfs(tickers)\n",
    "        rnn = PortfolioBuilder(preprocessed.shape[1], len(filt) + 1, preprocessed.shape[1])\n",
    "    rnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if checkpoint['sharpe']:\n",
    "        print(\"Loaded '{}' with a Sharpe loss of {}.\".format(model_file, checkpoint['loss']))\n",
    "    else:\n",
    "        print(\"Loaded '{}' with an aggressive loss of {}.\".format(model_file, checkpoint['loss']))        \n",
    "    \n",
    "hidden = rnn.init_hidden()\n",
    "rnn.eval()\n",
    "\n",
    "X = normalize(preprocessed)\n",
    "n = X.shape[0]\n",
    "print(\"Using all {} days.\".format(n))\n",
    "\n",
    "all_predictions = np.zeros(len(filt)+1)\n",
    "for i in range(n):\n",
    "    x = torch.Tensor(np.array(X.iloc[i])).to(torch.float32)\n",
    "    prediction, hidden = rnn(x, hidden)\n",
    "    all_predictions += np.array(prediction.squeeze().detach())\n",
    "\n",
    "total_assets = 3600/3\n",
    "print(\"Total assets: {} EUR\".format(total_assets))\n",
    "prediction = np.array(prediction.detach()).flatten() * total_assets\n",
    "all_predictions = all_predictions / n * total_assets\n",
    "\n",
    "portfolio = {}\n",
    "averages = {}\n",
    "for i in range(len(filt)):\n",
    "    portfolio[filt[i]] = prediction[i]\n",
    "    averages[filt[i]] = all_predictions[i]\n",
    "portfolio[\"EUR CASH\"] = prediction[len(filt)]\n",
    "averages[\"EUR CASH\"] = all_predictions[len(filt)]\n",
    "print(\"Averages: \" + str(averages))\n",
    "print(\"Portfolio: \" + str(portfolio))\n",
    "\n",
    "plt.bar(portfolio.keys(), portfolio.values())\n",
    "plt.title(\"Today's portfolio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c37b17-8fe4-4d2e-bbef-73214dd21c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
